{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling with LDA and NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: Much of this code was modified from Aneesha Bakharia and her blog post on Topic Modeling   \n",
    "  https://medium.com/mlreview/topic-modeling-with-scikit-learn-e80d33668730"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things to try\n",
    "# - different amounts of topics\n",
    "# - different corpuses (full_text, be_here_now, quotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose path to data\n",
    "path = 'full_text.txt'\n",
    "#path = 'quotes.txt'\n",
    "#path = 'be_here_now.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file\n",
    "f = open(path, encoding='utf-8')\n",
    "\n",
    "# Instantiate documents list\n",
    "documents = []\n",
    "\n",
    "# Iterate through each line (document), strip newlines, and append to raw_text list\n",
    "for line in f:\n",
    "    documents.append(line.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of extra newlines that resulted in empty strings\n",
    "documents = [doc for doc in documents if doc != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1195\n"
     ]
    }
   ],
   "source": [
    "# Check length of documents\n",
    "print('Number of documents:', len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean + preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(document_string):\n",
    "    \"\"\"\n",
    "    Function that takes in a document in\n",
    "    the form of a string, and preprocesses\n",
    "    it, returning a clean string ready\n",
    "    to be used to fit a CountVectorizer.\n",
    "    \n",
    "    Preprocessing includes:\n",
    "    - lowercasing text\n",
    "    - eliminating punctuation\n",
    "    - dealing with edge case punctuation\n",
    "      and formatting\n",
    "    - replacing contractions with\n",
    "      the proper full words\n",
    "      \n",
    "    :param: document_string: str\n",
    "    \n",
    "    :returns: cleaned_text: str\n",
    "    \"\"\"\n",
    "    # Make text lowercase\n",
    "    raw_text = document_string.lower()\n",
    "\n",
    "    # Replace encoding error with a space\n",
    "    raw_text = raw_text.replace('\\xa0', ' ')\n",
    "    \n",
    "    # Make hypnenated versions non-hyphenated\n",
    "    raw_text = raw_text.replace('mahara-ji', 'maharaji')\n",
    "    raw_text = raw_text.replace('maharaj-ji', 'maharaji')\n",
    "\n",
    "    # Normalize period formatting\n",
    "    raw_text = raw_text.replace('.', '')\n",
    "\n",
    "    # Replace exclamation point with a space\n",
    "    raw_text = raw_text.replace('!', ' ')\n",
    "\n",
    "    # Replace slashes with empty\n",
    "    raw_text = raw_text.replace('/', '')\n",
    "\n",
    "    # Replace questin marks with empty\n",
    "    raw_text = raw_text.replace('??', ' ')\n",
    "    raw_text = raw_text.replace('?', ' ')\n",
    "\n",
    "    # Replace dashes with space\n",
    "    raw_text = raw_text.replace('-', ' ')\n",
    "    raw_text = raw_text.replace('—', ' ')\n",
    "\n",
    "    # Replace ... with empty\n",
    "    raw_text = raw_text.replace('…', '')\n",
    "    raw_text = raw_text.replace('...', '')\n",
    "    \n",
    "    # Replace = with 'equals'\n",
    "    raw_text = raw_text.replace('=', 'equals')\n",
    "\n",
    "    # Replace commas with empty\n",
    "    raw_text = raw_text.replace(',', '')\n",
    "    \n",
    "    # Replace ampersand with and\n",
    "    raw_text = raw_text.replace('&', 'and')\n",
    "\n",
    "    # Replace semi-colon with empty\n",
    "    raw_text = raw_text.replace(';', '')\n",
    "    \n",
    "    # Replace colon with empty\n",
    "    raw_text = raw_text.replace(':', '')\n",
    "\n",
    "    # Get rid of brackets\n",
    "    raw_text = raw_text.replace('[', '')\n",
    "    raw_text = raw_text.replace(']', '')\n",
    "    \n",
    "    # Replace parentheses with empty\n",
    "    raw_text = raw_text.replace('(', '')\n",
    "    raw_text = raw_text.replace(')', '')\n",
    "    \n",
    "    # Replace symbols with letters\n",
    "    raw_text = raw_text.replace('$', 's')\n",
    "    raw_text = raw_text.replace('¢', 'c')\n",
    "\n",
    "    # Replace quotes with nothing\n",
    "    raw_text = raw_text.replace('“', '')\n",
    "    raw_text = raw_text.replace('”', '')\n",
    "    raw_text = raw_text.replace('\"', '')\n",
    "    raw_text = raw_text.replace(\"‘\", \"\")\n",
    "\n",
    "    # Get rid of backslashes indicating contractions\n",
    "    raw_text = raw_text.replace(r'\\\\', '')\n",
    "\n",
    "    # Replace extra spaces with single space\n",
    "    raw_text = raw_text.replace('   ', ' ')\n",
    "    raw_text = raw_text.replace('  ', ' ')\n",
    "\n",
    "    # Some apostrophes are of a different type --> ’ instead of '\n",
    "    raw_text = raw_text.replace(\"’\", \"'\")\n",
    "\n",
    "    # Replace contractions with full words, organized alphabetically\n",
    "    raw_text = raw_text.replace(\"can't\", 'cannot')\n",
    "    raw_text = raw_text.replace(\"didn't\", 'did not')\n",
    "    raw_text = raw_text.replace(\"doesn't\", 'does not')\n",
    "    raw_text = raw_text.replace(\"don't\", 'do not')\n",
    "    raw_text = raw_text.replace(\"hasn't\", 'has not')\n",
    "    raw_text = raw_text.replace(\"he's\", 'he is')\n",
    "    raw_text = raw_text.replace(\"i'd\", 'i would')\n",
    "    raw_text = raw_text.replace(\"i'll\", 'i will')\n",
    "    raw_text = raw_text.replace(\"i'm\", 'i am')\n",
    "    raw_text = raw_text.replace(\"isn't\", 'is not')\n",
    "    raw_text = raw_text.replace(\"it's\", 'it is')\n",
    "    raw_text = raw_text.replace(\"nobody's\", 'nobody is')\n",
    "    raw_text = raw_text.replace(\"she's\", 'she is')\n",
    "    raw_text = raw_text.replace(\"shouldn't\", 'should not')\n",
    "    raw_text = raw_text.replace(\"that'll\", 'that will')\n",
    "    raw_text = raw_text.replace(\"that's\", 'that is')\n",
    "    raw_text = raw_text.replace(\"there'd\", 'there would')\n",
    "    raw_text = raw_text.replace(\"they're\", 'they are')\n",
    "    raw_text = raw_text.replace(\"there's\", 'there are')\n",
    "    raw_text = raw_text.replace(\"wasn't\", 'was not')\n",
    "    raw_text = raw_text.replace(\"we'd\", 'we would')\n",
    "    raw_text = raw_text.replace(\"we'll\", 'we will')\n",
    "    raw_text = raw_text.replace(\"we're\", 'we are')\n",
    "    raw_text = raw_text.replace(\"we've\", 'we have')\n",
    "    raw_text = raw_text.replace(\"you'll\", 'you will')\n",
    "    raw_text = raw_text.replace(\"you're\", 'you are')\n",
    "    raw_text = raw_text.replace(\"you've\", 'you have')\n",
    "\n",
    "    # Fix other contractions\n",
    "    raw_text = raw_text.replace(\"'s\", ' is')\n",
    "    \n",
    "    cleaned_text = raw_text\n",
    "    \n",
    "    return(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean all documents\n",
    "cleaned_documents = [clean_text(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of characters in a document is: 313\n",
      "The average number of words in a document is: 62\n"
     ]
    }
   ],
   "source": [
    "# Find average length of quotes by word and by characters\n",
    "# Initialize count lists\n",
    "char_length = []\n",
    "word_length = []\n",
    "\n",
    "# Iterate through each quote and find lengths\n",
    "for doc in cleaned_documents:\n",
    "    char_length.append(len(doc))\n",
    "    word_length.append(len(doc.split(' ')))\n",
    "    \n",
    "# Calculate means\n",
    "char_mean = int(round(np.mean(char_length)))\n",
    "word_mean = int(round(np.mean(word_length)))\n",
    "\n",
    "# View averages\n",
    "print('The average number of characters in a document is:', char_mean)\n",
    "print('The average number of words in a document is:', word_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    \"\"\"\n",
    "    Function that takes in a model, feature_names,\n",
    "    and no_top_words and displays topics and top\n",
    "    words in a readible fashion.\n",
    "    \n",
    "    :param: model: sklearn.decomposition\n",
    "    :param: feature_names: list\n",
    "    :param: no_top_words: int\n",
    "    \n",
    "    :returns: printed topics and top words\n",
    "    \"\"\"\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of features\n",
    "no_features = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMF using tf-idf\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(cleaned_documents)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "# Set number of topics\n",
    "no_topics = 20\n",
    "\n",
    "# Run NMF\n",
    "nmf = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "just say like come really people soul look awareness ego\n",
      "\n",
      "Topic 1:\n",
      "love person beloved everybody fear getting power consciously goes consciousness\n",
      "\n",
      "Topic 2:\n",
      "suffering relieve compassion root close deal trip pain situation joy\n",
      "\n",
      "Topic 3:\n",
      "moment comes death affecting deeply fully experience present creative mind\n",
      "\n",
      "Topic 4:\n",
      "going simple mantra like left begin process meet oh instead\n",
      "\n",
      "Topic 5:\n",
      "heart mind open spiritual emotional use human witness soul comes\n",
      "\n",
      "Topic 6:\n",
      "thought think breath thinking god mind home hear completely day\n",
      "\n",
      "Topic 7:\n",
      "way saying works seeing got attachment set experience action jesus\n",
      "\n",
      "Topic 8:\n",
      "life world live living awaken experiences transformation people unfolding deeply\n",
      "\n",
      "Topic 9:\n",
      "place energy form universe doing inside pure exists got atman\n",
      "\n",
      "Topic 10:\n",
      "thoughts senses content identification awareness identify just reality got set\n",
      "\n",
      "Topic 11:\n",
      "guru god man separate meet seeker speak point met form\n",
      "\n",
      "Topic 12:\n",
      "right doing inside message dance righteousness need center speaking baby\n",
      "\n",
      "Topic 13:\n",
      "know said experience did mother everybody possible somebody takes maharaji\n",
      "\n",
      "Topic 14:\n",
      "time space eternal got long awareness step living consciousness bliss\n",
      "\n",
      "Topic 15:\n",
      "thing say offer funny trip desire let secret wrote consciousness\n",
      "\n",
      "Topic 16:\n",
      "truth perfect journey sacrifice spiritual free deeper listen people human\n",
      "\n",
      "Topic 17:\n",
      "want people pain today free getting awaken power peace come\n",
      "\n",
      "Topic 18:\n",
      "faith meditation strong experiences hope journey moments grace doubt ye\n",
      "\n",
      "Topic 19:\n",
      "work does attachment help people statement sense god really feeling\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View results\n",
    "no_top_words = 10\n",
    "display_topics(nmf, tfidf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=no_features, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(cleaned_documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "\n",
    "# Run LDA\n",
    "lda = LatentDirichletAllocation(n_topics=no_topics, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "sound fact structure training identified works slowly evening heaven maharaji\n",
      "\n",
      "Topic 1:\n",
      "awareness mind consciousness thing loving energy thinking humor mantra sacrifice\n",
      "\n",
      "Topic 2:\n",
      "plane let physical astral idea causal pure channel consciousness yes\n",
      "\n",
      "Topic 3:\n",
      "fact pick telephone want power life minute long suffering possible\n",
      "\n",
      "Topic 4:\n",
      "listening chakra tuning beauty fourth starting butterfly energy caterpillar instrument\n",
      "\n",
      "Topic 5:\n",
      "surrender fear line golf end chakra certain fine interested forces\n",
      "\n",
      "Topic 6:\n",
      "desire says christ guru father ceremony ye lord ouspensky thou\n",
      "\n",
      "Topic 7:\n",
      "clock place hearing mother ear looked dying illusion watch saw\n",
      "\n",
      "Topic 8:\n",
      "pain day grace new stop thing wow york want say\n",
      "\n",
      "Topic 9:\n",
      "moment suffering heart way hear universe place comes open form\n",
      "\n",
      "Topic 10:\n",
      "drama qualities said man answer guy future butterfly came know\n",
      "\n",
      "Topic 11:\n",
      "life helping niyamas yamas try audience takes purification karma hold\n",
      "\n",
      "Topic 12:\n",
      "happened paradox vibrations exquisite perfection talking trip store beings says\n",
      "\n",
      "Topic 13:\n",
      "god just eating trained light days mahatma sita ram gandhi\n",
      "\n",
      "Topic 14:\n",
      "singing dancing story growing fall awakening level astral teaching dying\n",
      "\n",
      "Topic 15:\n",
      "dance doing dancing later talking forget collect right butterfly going\n",
      "\n",
      "Topic 16:\n",
      "faith good game meditation called example pure wisdom hope george\n",
      "\n",
      "Topic 17:\n",
      "world giggle awareness creative earth live moment cosmic accidents buddha\n",
      "\n",
      "Topic 18:\n",
      "just love people like say going know way time think\n",
      "\n",
      "Topic 19:\n",
      "channel roles teacher child process beautiful gone unfolding teachings play\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View results\n",
    "no_top_words = 10\n",
    "display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
